<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Honeypot Mechanism for additional protocol security | Reclaim Protocol Official Blog</title>
<meta name="keywords" content="">
<meta name="description" content="To discourage attestors from certifying false claims, we want to make this dishonest behavior as financially risky as possible. While the Reporting Mechanism already provides some such financial risk, even more risk can be added through the Honeypot Mechanism. This mechanism which allows users to prepare trap claims, and attestors who accept a bribe to certify a trap claim will get caught in the trap. Trapped attestors are then charged a penalty, and the penalty is given to the user who trapped them as a reward.">
<meta name="author" content="">
<link rel="canonical" href="https://blog.reclaimprotocol.org/posts/honey-pot/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css" integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U&#43;6hYRq/Ez/nm5vg=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://blog.reclaimprotocol.org/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://blog.reclaimprotocol.org/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://blog.reclaimprotocol.org/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://blog.reclaimprotocol.org/apple-touch-icon.png">
<link rel="mask-icon" href="https://blog.reclaimprotocol.org/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Honeypot Mechanism for additional protocol security" />
<meta property="og:description" content="To discourage attestors from certifying false claims, we want to make this dishonest behavior as financially risky as possible. While the Reporting Mechanism already provides some such financial risk, even more risk can be added through the Honeypot Mechanism. This mechanism which allows users to prepare trap claims, and attestors who accept a bribe to certify a trap claim will get caught in the trap. Trapped attestors are then charged a penalty, and the penalty is given to the user who trapped them as a reward." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://blog.reclaimprotocol.org/posts/honey-pot/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-16T13:54:06-08:00" />
<meta property="article:modified_time" content="2024-01-16T13:54:06-08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Honeypot Mechanism for additional protocol security"/>
<meta name="twitter:description" content="To discourage attestors from certifying false claims, we want to make this dishonest behavior as financially risky as possible. While the Reporting Mechanism already provides some such financial risk, even more risk can be added through the Honeypot Mechanism. This mechanism which allows users to prepare trap claims, and attestors who accept a bribe to certify a trap claim will get caught in the trap. Trapped attestors are then charged a penalty, and the penalty is given to the user who trapped them as a reward."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://blog.reclaimprotocol.org/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Honeypot Mechanism for additional protocol security",
      "item": "https://blog.reclaimprotocol.org/posts/honey-pot/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Honeypot Mechanism for additional protocol security",
  "name": "Honeypot Mechanism for additional protocol security",
  "description": "To discourage attestors from certifying false claims, we want to make this dishonest behavior as financially risky as possible. While the Reporting Mechanism already provides some such financial risk, even more risk can be added through the Honeypot Mechanism. This mechanism which allows users to prepare trap claims, and attestors who accept a bribe to certify a trap claim will get caught in the trap. Trapped attestors are then charged a penalty, and the penalty is given to the user who trapped them as a reward.",
  "keywords": [
    
  ],
  "articleBody": "To discourage attestors from certifying false claims, we want to make this dishonest behavior as financially risky as possible. While the Reporting Mechanism already provides some such financial risk, even more risk can be added through the Honeypot Mechanism. This mechanism which allows users to prepare trap claims, and attestors who accept a bribe to certify a trap claim will get caught in the trap. Trapped attestors are then charged a penalty, and the penalty is given to the user who trapped them as a reward.\nHere is how the Honeypot mechanism works. For reasons that will be clear shortly, at any time users are allowed to submit a cryptographic commitment of an encryption key to the blockchain. A cryptographic commitment is a way someone can hide some secret information, but they are able to reveal the true value of the information at any future time. It’s like putting something in a locked box and leaving the box in a public space, and you can later unlock the box and show everyone what was in it. The important part is that everyone will know that the contents of the box could not have been tampered with between it being locked and unlocked.\nThe encryption keys that users can commit to will serve to set up traps that can later be sprung on dishonest attestors.\nNow, suppose a user has certified a false claim by bribing the attestors. The user can then issue what we call a challenge to the attestors. When an attestor is challenged, they must provide:\nThe encrypted data $D$ that was used for the claim (if the attestor was being honest, this is the data that was returned by the website.) The ZK-proof that the user created and shared with the attestor (As a technical aside, for the Honeypot mechanism to work we need to add an additional step to the main Reclaim protocol where the user must sign $D$ and send this signature to the attestor, to demonstrate that they signed off on the data appearing authentic. The purpose of this will be clear later.)\nOnce the attestor has provided this information, it can be verified that the encrypted data and the ZK-proof indeed show that the claim is true.\nIf the verification does not work, or if the attestor does not provide the information within some given time frame, then the attestor is marked as trapped. When an attestor is trapped, they are charged a set penalty which is taken from their staked funds.\nOn the other hand, suppose the attestor does provide the information in time and that the verification works. Then, the user has an opportunity to reveal an encryption key $k$ that they had previously committed to. It can then be verified whether this key properly decrypts the encrypted data $D$ that the attestor provided.\nIf $k$ does properly decrypt $D$, then some dishonesty must be afoot! This is because there is no way the user could have predicted in advance what the encryption key for the data would be, since this key is decided during the TLS handshake between the user and the website. In other words, the user locked away $k$ at some point in the past, but the actual encryption key for the data returned by the website would have been created at some future time.\nSo what must have happened? Well, the only explanation is that the user had created some false encrypted data, sent it to the attestor, and got the attestor to sign off on the claim using the false data instead. Because the user got to create this false data themselves, they could encrypt it using the key $k$ they had committed to. Therefore, the attestor must have been dishonest, so the attestor is marked as trapped.\nTo summarize what we’ve covered so far, when a user tries to bribe an attestor to sign off on a false claim using fake data that the user supplies, the attestor will have to worry that they are being setup in a trap.\nBut what if an attestor is smart and says to the user: sure I’ll sign off on your false claim, but only if you let me encrypt the fake data using a key of my own choosing, so I can be sure that I’m not being trapped. How can this strategy be stopped?\nWe can use the same strategy and let attestors trap users! After a claim has been certified, any attestor for the claim can issue a challenge to the user. When an attestor challenges the user, no input is required from the user, but the attestor must provide:\nThe encrypted data $D$ that was used for the claim (and which was signed by the user) An encryption key $k'$ It can then be verified that $k’$ properly decrypts $D$, and if this is true, then the user is marked as trapped. Why? Because during the normal, honest operation of the Reclaim protocol, the attestor is not able to learn the value of the encryption key for the data returned by the website. The only way the attestor could know the key is if they themselves had encrypted some fake data, and we know the user agreed to this happening because the user had signed this data knowing it was fake. (They would know it’s fake because they know the real encryption key resulting from the TLS handshake, and can verify that this key does not work for the fake data.)\nSummarizing everything together, suppose a user wants to bribe some attestors to certify a false claim, and the attestors are willing to accept the bribe for this. However, they now have a problem:\nIf the user creates the fake data using a secret key of their own, then the attestors will worry that the user had already posted a commitment to this key to the blockchain, and they are being set up for a trap. If the the fake data is made using a key that is not kept secret from the attestors, then the user will worry that any attestor can trap them after the claim is certified. So, there is no way (we know of) for both the user and the attestors to trust that they are not being trapped, which creates a disincentive for dishonest behavior.\nWhile people may try to come up with clever new ways to avoid getting trapped, the financial reward for catching others in traps will incentivize people to come up with clever new ways to trap! And critically, anyone behaving honestly will have nothing to worry about.\n",
  "wordCount" : "1102",
  "inLanguage": "en",
  "datePublished": "2024-01-16T13:54:06-08:00",
  "dateModified": "2024-01-16T13:54:06-08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://blog.reclaimprotocol.org/posts/honey-pot/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Reclaim Protocol Official Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://blog.reclaimprotocol.org/favicon.ico"
    }
  }
}
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>


</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://blog.reclaimprotocol.org/" accesskey="h" title="Reclaim Protocol Official Blog (Alt + H)">Reclaim Protocol Official Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Honeypot Mechanism for additional protocol security
    </h1>
    <div class="post-meta"><span title='2024-01-16 13:54:06 -0800 PST'>January 16, 2024</span>

</div>
  </header> 
  <div class="post-content"><p>To discourage attestors from certifying false claims, we want to make this dishonest behavior as financially risky as possible. While the <a href="https://www.notion.so/Reporting-Mechanism-51306b54f4b94a4cba81090f7461acca?pvs=21">Reporting Mechanism</a> already provides some such financial risk, even more risk can be added through the Honeypot Mechanism. This mechanism which allows users to prepare trap claims, and attestors who accept a bribe to certify a trap claim will get caught in the trap. Trapped attestors are then charged a penalty, and the penalty is given to the user who trapped them as a reward.</p>
<p><img loading="lazy" src="/images/honey-pot-1.jpg" alt="Honey Pot"  />
</p>
<p>Here is how the Honeypot mechanism works. For reasons that will be clear shortly, at any time users are allowed to submit a <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>cryptographic commitment</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> of an <strong><strong><strong><strong><strong><strong><strong>encryption key</strong></strong></strong></strong></strong></strong></strong> to the blockchain. A cryptographic commitment is a way someone can hide some secret information, but they are able to reveal the true value of the information at any future time. It’s like putting something in a locked box and leaving the box in a public space, and you can later unlock the box and show everyone what was in it. The important part is that everyone will know that the contents of the box could not have been tampered with between it being locked and unlocked.</p>
<p><img loading="lazy" src="/images/honey-pot-2.png" alt=""  />
</p>
<p>The encryption keys that users can commit to will serve to set up traps that can later be sprung on dishonest attestors.</p>
<p>Now, suppose a user has certified a false claim by bribing the attestors. The user can then issue what we call a <em><strong><strong><strong><strong>challenge</strong></strong></strong></strong></em> to the attestors. When an attestor is challenged, they must provide:</p>
<ol>
<li>The encrypted data $D$ that was used for the claim (if the attestor was being honest, this is the data that was returned by the website.)</li>
<li>The ZK-proof that the user created and shared with the attestor</li>
</ol>
<p>(As a technical aside, for the Honeypot mechanism to work we need to add an additional step to the main Reclaim protocol where the user must sign $D$ and send this signature to the attestor, to demonstrate that they signed off on the data appearing authentic. The purpose of this will be clear later.)</p>
<p>Once the attestor has provided this information, it can be verified that the encrypted data and the ZK-proof indeed show that the claim is true.</p>
<p><img loading="lazy" src="/images/honey-pot-3.png" alt=""  />
</p>
<p>If the verification does not work, or if the attestor does not provide the information within some given time frame, then the attestor is marked as <em><strong><strong><strong>trapped</strong></strong></strong></em>. When an attestor is trapped, they are charged a set penalty which is taken from their staked funds.</p>
<p>On the other hand, suppose the attestor does provide the information in time and that the verification works. Then, the user has an opportunity to reveal an encryption key $k$ that they had previously committed to. It can then be verified whether this key properly decrypts the encrypted data $D$ that the attestor provided.</p>
<p>If $k$ does properly decrypt $D$, then some dishonesty must be afoot! This is because there is no way the user could have predicted in advance what the encryption key for the data would be, since this key is decided during the TLS handshake between the user and the website. In other words, the user locked away $k$ at some point in the past, but the actual encryption key for the data returned by the website would have been created at some future time.</p>
<p>So what must have happened? Well, the only explanation is that the user had created some false encrypted data, sent it to the attestor, and got the attestor to sign off on the claim using the false data instead. Because the user got to create this false data themselves, they could encrypt it using the key $k$ they had committed to. Therefore, the attestor must have been dishonest, so the attestor is marked as trapped.</p>
<p>To summarize what we’ve covered so far, when a user tries to bribe an attestor to sign off on a false claim using fake data that the user supplies, the attestor will have to worry that they are being setup in a trap.</p>
<hr>
<p>But what if an attestor is smart and says to the user: sure I’ll sign off on your false claim, but only if you let me encrypt the fake data using a key of my own choosing, so I can be sure that I’m not being trapped. How can this strategy be stopped?</p>
<p>We can use the same strategy and let attestors trap users! After a claim has been certified, any attestor for the claim can issue a challenge to the user. When an attestor challenges the user, no input is required from the user, but the attestor must provide:</p>
<ol>
<li>The encrypted data $D$ that was used for the claim (and which was signed by the user)</li>
<li>An encryption key $k'$</li>
</ol>
<p>It can then be verified that $k&rsquo;$ properly decrypts $D$, and if this is true, then the user is marked as trapped. Why? Because during the normal, honest operation of the Reclaim protocol, the attestor is not able to learn the value of the encryption key for the data returned by the website. The only way the attestor could know the key is if they themselves had encrypted some fake data, and we know the user agreed to this happening because the user had signed this data knowing it was fake. (They would know it’s fake because they know the real encryption key resulting from the TLS handshake, and can verify that this key does not work for the fake data.)</p>
<p>Summarizing everything together, suppose a user wants to bribe some attestors to certify a false claim, and the attestors are willing to accept the bribe for this. However, they now have a problem:</p>
<ol>
<li>If the user creates the fake data using a secret key of their own, then the attestors will worry that the user had already posted a commitment to this key to the blockchain, and they are being set up for a trap.</li>
<li>If the the fake data is made using a key that is not kept secret from the attestors, then the user will worry that any attestor can trap them after the claim is certified.</li>
</ol>
<p>So, there is no way (we know of) for both the user and the attestors to trust that they are not being trapped, which creates a disincentive for dishonest behavior.</p>
<p><img loading="lazy" src="/images/honey-pot-4.png" alt=""  />
</p>
<p>While people may try to come up with clever new ways to avoid getting trapped, the financial reward for catching others in traps will incentivize people to come up with clever new ways to trap! And critically, anyone behaving honestly will have nothing to worry about.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://blog.reclaimprotocol.org/">Reclaim Protocol Official Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
