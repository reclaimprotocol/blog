<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>RFP - AI friendly ZK Captcha | Reclaim Protocol Official Blog</title>
<meta name="keywords" content="">
<meta name="description" content="Madhavan (Mads) Malolan Which side is up? Captchas are getting so hard that only AIs will be able to solve it. The key premise of this post is that it is getting increasingly important for AI agents to be able to access web products on behalf of the user. Captchas are an antipattern. They are not any good at keeping AI bots out anyway, at the same time they&rsquo;re detrimental to productivity.">
<meta name="author" content="">
<link rel="canonical" href="https://blog.reclaimprotocol.org/posts/zk-captcha/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://blog.reclaimprotocol.org/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://blog.reclaimprotocol.org/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://blog.reclaimprotocol.org/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://blog.reclaimprotocol.org/apple-touch-icon.png">
<link rel="mask-icon" href="https://blog.reclaimprotocol.org/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://blog.reclaimprotocol.org/posts/zk-captcha/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<meta property="og:title" content="RFP - AI friendly ZK Captcha" />
<meta property="og:description" content="Madhavan (Mads) Malolan Which side is up? Captchas are getting so hard that only AIs will be able to solve it. The key premise of this post is that it is getting increasingly important for AI agents to be able to access web products on behalf of the user. Captchas are an antipattern. They are not any good at keeping AI bots out anyway, at the same time they&rsquo;re detrimental to productivity." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://blog.reclaimprotocol.org/posts/zk-captcha/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-03-12T16:42:01-04:00" />
<meta property="article:modified_time" content="2024-03-12T16:42:01-04:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="RFP - AI friendly ZK Captcha"/>
<meta name="twitter:description" content="Madhavan (Mads) Malolan Which side is up? Captchas are getting so hard that only AIs will be able to solve it. The key premise of this post is that it is getting increasingly important for AI agents to be able to access web products on behalf of the user. Captchas are an antipattern. They are not any good at keeping AI bots out anyway, at the same time they&rsquo;re detrimental to productivity."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://blog.reclaimprotocol.org/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "RFP - AI friendly ZK Captcha",
      "item": "https://blog.reclaimprotocol.org/posts/zk-captcha/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "RFP - AI friendly ZK Captcha",
  "name": "RFP - AI friendly ZK Captcha",
  "description": "Madhavan (Mads) Malolan Which side is up? Captchas are getting so hard that only AIs will be able to solve it. The key premise of this post is that it is getting increasingly important for AI agents to be able to access web products on behalf of the user. Captchas are an antipattern. They are not any good at keeping AI bots out anyway, at the same time they\u0026rsquo;re detrimental to productivity.",
  "keywords": [
    
  ],
  "articleBody": " Madhavan (Mads) Malolan Which side is up? Captchas are getting so hard that only AIs will be able to solve it. The key premise of this post is that it is getting increasingly important for AI agents to be able to access web products on behalf of the user. Captchas are an antipattern. They are not any good at keeping AI bots out anyway, at the same time they’re detrimental to productivity. Companies like Induced AI have been able to make life much easier by knocking off the easy mundane tasks for you.\nSo, let’s get rid of captchas? I understand the reason of having a captcha. It makes a digital resource scarce - by requiring only a human to be able to use it. If the cost of using any digital resource or service becomes zero, it becomes way too cheap to screw with the service - think spam and abuse. There’s no disincentive to misbehave.\nOne way to combat that is to attach a micropayment to every https request. It is a plausible solution and has been around for a long while.\nCan we do better? I think so.\nSign every HTTPS request. Ofcourse. Who hasn’t thought of that? Let’s assume every browser implements a i-dont-want-to-call-it-a-wallet. That is, there is a private key for every user on their browser. Now this private key adds a header to every https request it makes, with the signature of the request.\nThat in itself doesn’t solve the problem. Someone can spin up millions of bots and create millions of private keys at no cost.\nBut, every browser public key is associated with an identity. You can make your identity stronger by attaching your national id, employment status, purchase history etc. All the contents of the identity like the national id itself, purchase history etc aren’t public. But a commitment to them is. This can be achieved using Reclaim Protocol. These commitments can be stored on chain for later use.\nThe key insight is, one proof can be added to exactly one identity. That is, your national id can be used exactly once. If it has been linked to a browser public key, it cannot be linked to another without invalidating the previous public key.\nThe website that receives this https request will check the header and calculate the identity strength based on the quantity and quality of proofs linked with the public key. If the score is above a threshold, the user is allowed to access the full site. If not, they get access only to limited parts of the site - e.g. they can only read, not post.\nHowever, when the the user (human or bot) that is using the said browser key misbehaves on the website - the website can flag the user as abusive and publish a list. This list consists of the public keys of the abusive users and proof of their abusive behaviour using the redacted signed requests (using ZKPs) that was sent using this public key. Any other website can import this list from any other website. This happens all the time in IP Blocklisting. Cloudflare, Google etc share IP Blocklists.\nWhen a public key is reported as abusive by one website, all the websites that import that list can update their scoring of the user’s identity. They may do this by fetching all the proofs linked to the public key from the blockchain. They may mark all the linked proofs a abusive and re-calculate the score for the user.\nThat way, if a user uses a public key with multiple proofs linked misbehaves on a website, they will incur losses to all their proofs and all the identity scores that will be calculated by other websites in future. So, even if they create a new browser and a new public key, the proofs they will be able to link are already tainted.\nThis may seem like a recipe for censored on one platform, censored on all platforms kind of a situation. However, the implementation of the middleware on apache or nginx should be such that each website is able to determine its own logic for how to import lists from other websites. If someone is censored on twitter for a political opinion, twitter not only has to publish the public key but also the redacted https request itself. So, facebook that may be importing this blocklist from twitter may have its own logic to determine whether or not it wants to censor the said public key. But if twitter blocklists a user because of a ddos attempt, that is probably relevant information to facebook too.\nThis is a public good that ought to be built. Someone is going to build it, for sure.\n",
  "wordCount" : "789",
  "inLanguage": "en",
  "datePublished": "2024-03-12T16:42:01-04:00",
  "dateModified": "2024-03-12T16:42:01-04:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://blog.reclaimprotocol.org/posts/zk-captcha/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Reclaim Protocol Official Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://blog.reclaimprotocol.org/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://blog.reclaimprotocol.org/" accesskey="h" title="Reclaim Protocol Official Blog (Alt + H)">Reclaim Protocol Official Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      RFP - AI friendly ZK Captcha
    </h1>
    <div class="post-meta"><span title='2024-03-12 16:42:01 -0400 EDT'>March 12, 2024</span>

</div>
  </header> 
  <div class="post-content"><ul>
<li>Madhavan (Mads) Malolan</li>
</ul>
<p>Which side is up? Captchas are getting so hard that only AIs will be able to solve it.
The key premise of this post is that it is getting increasingly important for AI agents to be able to access web products on behalf of the user. Captchas are an antipattern. They are not any good at keeping AI bots out anyway, at the same time they&rsquo;re detrimental to productivity. Companies like <a href="https://www.induced.ai/">Induced AI</a> have been able to make life much easier by knocking off the easy mundane tasks for you.</p>
<p>So, let&rsquo;s get rid of captchas?
I understand the reason of having a captcha. It makes a digital resource scarce - by requiring only a human to be able to use it. If the cost of using any digital resource or service becomes zero, it becomes way too cheap to screw with the service - think spam and abuse. There&rsquo;s no disincentive to misbehave.</p>
<p>One way to combat that is to attach a micropayment to every https request. It is a plausible solution and has been <a href="https://wordpress.org/plugins/paid-membership/">around for a long while</a>.</p>
<p>Can we do better? I think so.</p>
<p>Sign every HTTPS request. Ofcourse. Who hasn&rsquo;t thought of that?
Let&rsquo;s assume every browser implements a i-dont-want-to-call-it-a-wallet. That is, there is a private key for every user on their browser.
Now this private key adds a <code>header</code> to every https request it makes, with the signature of the request.</p>
<p>That in itself doesn&rsquo;t solve the problem. Someone can spin up millions of bots and create millions of private keys at no cost.</p>
<p>But, every browser public key is associated with an identity.
You can make your identity stronger by attaching your national id, employment status, purchase history etc. All the contents of the identity like the national id itself, purchase history etc aren&rsquo;t public. But a commitment to them is. This can be achieved using Reclaim Protocol. These commitments can be stored on chain for later use.</p>
<p>The key insight is, one proof can be added to exactly one identity. That is, your national id can be used exactly once. If it has been linked to a browser public key, it cannot be linked to another without invalidating the previous public key.</p>
<p>The website that receives this https request will check the header and calculate the identity strength based on the quantity and quality of proofs linked with the public key. If the score is above a threshold, the user is allowed to access the full site. If not, they get access only to limited parts of the site - e.g. they can only read, not post.</p>
<p>However, when the the user (human or bot) that is using the said browser key misbehaves on the website - the website can flag the user as abusive and publish a list. This list consists of the public keys of the abusive users and proof of their abusive behaviour using the redacted signed requests (using ZKPs) that was sent using this public key.
Any other website can import this list from any other website. This happens all the time in IP Blocklisting. Cloudflare, Google etc share IP Blocklists.</p>
<p>When a public key is reported as abusive by one website, all the websites that import that list can update their scoring of the user&rsquo;s identity. They may do this by fetching all the proofs linked to the public key from the blockchain. They may mark all the linked proofs a abusive and re-calculate the score for the user.</p>
<p>That way, if a user uses a public key with multiple proofs linked misbehaves on a website, they will incur losses to all their proofs and all the identity scores that will be calculated by other websites in future. So, even if they create a new browser and a new public key, the proofs they will be able to link are already tainted.</p>
<p>This may seem like a recipe for censored on one platform, censored on all platforms kind of a situation. However, the implementation of the middleware on apache or nginx should be such that each website is able to determine its own logic for how to import lists from other websites. If someone is censored on twitter for a political opinion, twitter not only has to publish the public key but also the redacted https request itself. So, facebook that may be importing this blocklist from twitter may have its own logic to determine whether or not it wants to censor the said public key. But if twitter blocklists a user because of a ddos attempt, that is probably relevant information to facebook too.</p>
<p>This is a public good that ought to be built. Someone is going to build it, for sure.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://blog.reclaimprotocol.org/">Reclaim Protocol Official Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
